# -*- coding: utf-8 -*-
"""
AN√ÅLISIS AVANZADO DE NOTICIAS DE INFOBAE AM√âRICA
Incluye:
- Visualizaciones b√°sicas (wordcloud, histogramas)
- An√°lisis de sentimiento
- Extracci√≥n de entidades (personas/lugares)
- Generaci√≥n de reporte PDF
"""

# =============================================================================
# SECCI√ìN 1: IMPORTAR LIBRER√çAS (Todas las necesarias)
# =============================================================================
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter
import re
import os
from datetime import datetime
from textblob import TextBlob  # Para an√°lisis de sentimiento
import spacy  # Para extraer entidades nombradas
from fpdf import FPDF  # Para generar reportes

# =============================================================================
# SECCI√ìN 2: CONFIGURACI√ìN INICIAL (Estilos y carpetas)
# =============================================================================
# Crear carpeta para gr√°ficos
os.makedirs('graficos', exist_ok=True)

# Configuraci√≥n de estilos matplotlib
plt.style.use('ggplot')
plt.rcParams['figure.dpi'] = 300  # Alta resoluci√≥n
plt.rcParams['font.size'] = 12

# Cargar modelo de lenguaje espa√±ol para spaCy
try:
    nlp = spacy.load("es_core_news_sm")
except:
    print("‚ö† Modelo spaCy no encontrado. Ejecuta: python -m spacy download es_core_news_sm")

# =============================================================================
# SECCI√ìN 3: FUNCIONES DE AN√ÅLISIS (Cada una con su prop√≥sito)
# =============================================================================
def cargar_datos():
    """Carga y preprocesa los datos desde el CSV"""
    try:
        df = pd.read_csv('infobae_noticias.csv')
        print("\n‚úÖ Datos cargados correctamente")
        print(f"üìä Total de noticias: {len(df)}")
        
        # Limpieza b√°sica de texto
        df['titulo_limpio'] = df['titulo'].apply(
            lambda x: re.sub(r'[^\w\s]', '', x.lower())
        )
        
        # Convertir fecha si existe
        if 'fecha_extraccion' in df.columns:
            df['fecha_extraccion'] = pd.to_datetime(df['fecha_extraccion'])
        
        return df
    
    except Exception as e:
        print(f"\n‚ùå Error al cargar datos: {str(e)}")
        exit()

def generar_wordcloud(texto):
    """Genera una nube de palabras desde el texto"""
    try:
        wordcloud = WordCloud(
            width=1200,
            height=600,
            background_color='white',
            colormap='viridis',
            max_words=200,
            collocations=False  # Evita frases comunes
        ).generate(texto)
        
        plt.figure(figsize=(15, 8))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        plt.title('Palabras m√°s frecuentes en titulares', pad=20)
        
        filename = f"graficos/wordcloud_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(filename, bbox_inches='tight')
        plt.close()
        return filename
    
    except Exception as e:
        print(f"‚ùå Error al generar wordcloud: {str(e)}")
        return None

def analizar_longitud_titulos(df):
    """Histograma de la longitud de los titulares"""
    try:
        df['longitud'] = df['titulo'].apply(len)
        
        plt.figure(figsize=(12, 6))
        n, bins, patches = plt.hist(
            df['longitud'], 
            bins=20, 
            color='#3498db', 
            edgecolor='#2980b9'
        )
        
        # Destacar la media
        mean_len = df['longitud'].mean()
        plt.axvline(mean_len, color='#e74c3c', linestyle='--', 
                   label=f'Media: {mean_len:.1f} caracteres')
        
        plt.xlabel('Longitud (caracteres)')
        plt.ylabel('Frecuencia')
        plt.title('Distribuci√≥n de longitud de titulares')
        plt.legend()
        
        filename = f"graficos/longitud_titulos_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(filename)
        plt.close()
        return filename
    
    except Exception as e:
        print(f"‚ùå Error en gr√°fico de longitud: {str(e)}")
        return None

def top_palabras(df, n=15):
    """Gr√°fico de las palabras m√°s frecuentes (excluyendo stopwords)"""
    try:
        stopwords = {
            'de', 'la', 'el', 'en', 'y', 'a', 'los', 'las', 
            'del', 'que', 'con', 'por', 'para'
        }
        
        words = [
            word for word in re.findall(r'\b\w+\b', ' '.join(df['titulo_limpio'])) 
            if word not in stopwords and len(word) > 3
        ]
        
        word_counts = Counter(words).most_common(n)
        
        plt.figure(figsize=(12, 6))
        bars = plt.barh(
            [w[0] for w in word_counts],
            [w[1] for w in word_counts],
            color='#2ecc71'
        )
        
        # A√±adir etiquetas de valor
        for bar in bars:
            width = bar.get_width()
            plt.text(width + 0.5, bar.get_y() + bar.get_height()/2,
                    f'{int(width)}', ha='left', va='center')
        
        plt.xlabel('Frecuencia')
        plt.title(f'Top {n} palabras en titulares')
        plt.gca().invert_yaxis()
        
        filename = f"graficos/top_palabras_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(filename)
        plt.close()
        return filename
    
    except Exception as e:
        print(f"‚ùå Error en top palabras: {str(e)}")
        return None

def analizar_sentimiento(df):
    """Calcula la polaridad del sentimiento en titulares"""
    try:
        df['sentimiento'] = df['titulo'].apply(
            lambda x: TextBlob(x).sentiment.polarity
        )
        
        plt.figure(figsize=(12, 6))
        plt.hist(
            df['sentimiento'], 
            bins=20, 
            color='#f39c12', 
            edgecolor='#e67e22',
            alpha=0.7
        )
        
        # Resaltar neutral (0) y extremos (-1, 1)
        for pos in [-1, 0, 1]:
            plt.axvline(pos, color='red', linestyle=':', alpha=0.5)
        
        plt.xlabel('Polaridad (-1 = Negativo, 1 = Positivo)')
        plt.ylabel('Frecuencia')
        plt.title('Distribuci√≥n de Sentimiento en Titulares')
        
        filename = f"graficos/sentimiento_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(filename)
        plt.close()
        return filename
    
    except Exception as e:
        print(f"‚ùå Error en an√°lisis de sentimiento: {str(e)}")
        return None

def extraer_entidades(df):
    """Identifica personas y lugares mencionados"""
    try:
        personas = []
        lugares = []
        
        for doc in nlp.pipe(df['titulo'].astype(str), batch_size=50):
            for ent in doc.ents:
                if ent.label_ == "PER":
                    personas.append(ent.text)
                elif ent.label_ == "LOC":
                    lugares.append(ent.text)
        
        # Gr√°fico para personas
        if personas:
            top_personas = Counter(personas).most_common(10)
            plt.figure(figsize=(12, 6))
            plt.barh(
                [p[0] for p in top_personas],
                [p[1] for p in top_personas],
                color='#9b59b6'
            )
            plt.title('Personas m√°s mencionadas')
            plt.gca().invert_yaxis()
            
            filename_p = f"graficos/personas_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.savefig(filename_p)
            plt.close()
        else:
            filename_p = None
        
        # Gr√°fico para lugares
        if lugares:
            top_lugares = Counter(lugares).most_common(10)
            plt.figure(figsize=(12, 6))
            plt.barh(
                [l[0] for l in top_lugares],
                [l[1] for l in top_lugares],
                color='#1abc9c'
            )
            plt.title('Lugares m√°s mencionados')
            plt.gca().invert_yaxis()
            
            filename_l = f"graficos/lugares_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.savefig(filename_l)
            plt.close()
        else:
            filename_l = None
        
        return filename_p, filename_l
    
    except Exception as e:
        print(f"‚ùå Error al extraer entidades: {str(e)}")
        return None, None

def generar_reporte(graficos):
    """Crea un PDF con todos los gr√°ficos generados"""
    try:
        pdf = FPDF()
        pdf.set_auto_page_break(auto=True, margin=15)
        
        # Portada
        pdf.add_page()
        pdf.set_font('Arial', 'B', 16)
        pdf.cell(0, 10, 'Reporte de An√°lisis: Infobae Am√©rica', 0, 1, 'C')
        pdf.ln(10)
        pdf.set_font('Arial', '', 12)
        pdf.multi_cell(0, 10, 
                      f"Fecha de generaci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                      f"Total noticias analizadas: {len(df)}")
        
        # A√±adir cada gr√°fico
        for img in graficos:
            if img and os.path.exists(img):
                pdf.add_page()
                pdf.image(img, x=10, y=10, w=180)
        
        # Guardar PDF
        pdf.output("reporte_analisis.pdf")
        print("\n‚úÖ Reporte generado: 'reporte_analisis.pdf'")
    
    except Exception as e:
        print(f"‚ùå Error al generar PDF: {str(e)}")

# =============================================================================
# SECCI√ìN 4: EJECUCI√ìN PRINCIPAL (Orquesta todo el an√°lisis)
# =============================================================================
if __name__ == "__main__":
    print("\n" + "="*60)
    print("AN√ÅLISIS AVANZADO DE INFOBAE AM√âRICA")
    print("="*60)
    
    # Cargar datos
    df = cargar_datos()
    text = ' '.join(df['titulo_limpio'])
    
    # Lista para almacenar gr√°ficos generados
    graficos_generados = []
    
    # Ejecutar an√°lisis
    print("\nüîç Ejecutando an√°lisis...")
    graficos_generados.append(generar_wordcloud(text))
    graficos_generados.append(analizar_longitud_titulos(df))
    graficos_generados.append(top_palabras(df))
    graficos_generados.append(analizar_sentimiento(df))
    
    # An√°lisis avanzado (opcional)
    personas_img, lugares_img = extraer_entidades(df)
    if personas_img:
        graficos_generados.append(personas_img)
    if lugares_img:
        graficos_generados.append(lugares_img)
    
    # Filtrar gr√°ficos no generados
    graficos_generados = [g for g in graficos_generados if g is not None]
    
    # Generar reporte final
    generar_reporte(graficos_generados)
    
    print("\n" + "="*60)
    print("üéâ ¬°An√°lisis completado con √©xito!")
    print(f"üìÇ Gr√°ficos guardados en: {os.path.abspath('graficos')}")
    print(f"üìÑ Reporte PDF generado: 'reporte_analisis.pdf'")
    print("="*60)